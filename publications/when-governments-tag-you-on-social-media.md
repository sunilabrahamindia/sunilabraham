---
layout: default
title: "When Governments Tag You on Social Media"
description: "A Business Standard opinion by Sunil Abraham on facial recognition, surveillance, accessibility and how platform architecture shapes the balance between public safety and civil liberties."
categories: [Media articles, Publications]
date: 2019-03-13
authors: ["Sunil Abraham"]
source: "Business Standard"
permalink: /publications/when-governments-tag-you-on-social-media/
created: 2025-11-30
---

**When Governments Tag You on Social Media** is an opinion piece by Sunil Abraham published in *Business Standard* on 13 March 2019. The article examines how face recognition technologies enable mass surveillance, the tension between public-interest uses and human-rights harms, and technical and policy approaches (including decentralised architectures) to reduce the risk of a global panopticon.

## Contents

1. [Article Details](#article-details)  
2. [Full Text](#full-text)  
3. [Context and Background](#context-and-background)  
4. [External Link](#external-link)

## Article Details

<dl class="media-details">
  <dt>ðŸ“° Published in:</dt>
  <dd><em>Business Standard</em></dd>

  <dt>ðŸ“… Date:</dt>
  <dd>13 March 2019</dd>

  <dt>ðŸ‘¤ Author:</dt>
  <dd>Sunil Abraham</dd>

  <dt>ðŸ“„ Type:</dt>
  <dd>Opinion</dd>

  <dt>ðŸ“° Newspaper Link:</dt>
  <dd>
    <a class="btn" href="https://www.business-standard.com/article/opinion/when-governments-tag-you-on-social-media-119031301137_1.html">
      Read Online
    </a> (Subscription required)
  </dd>
</dl>

## Full Text

<figure class="media-image">
  <img src="https://raw.githubusercontent.com/sunilabrahamindia/sunilabraham/main/publications/images/when-governments-tag-you-on-social-media.jpg"
       alt="Newspaper clipping of Sunil Abraham's article titled When Governments Tag You on Social Media, showing the printed column, a portrait of the author, and surrounding text in the Business Standard layout.">
  <figcaption>Newspaper copy of the article.</figcaption>
</figure>

<div class="highlighted-text" id="fulltext">

<p>Face recognition technology allows for remote, covert, non-consensual identification. In other words, like other forms of biometric technology, it can easily be used for mass and targeted surveillance. Internet giants such as Google, Facebook and Microsoft have large centralised databases containing photographs and video recordings of our faces. Using machine learning, they can easily identify us if one of their users were to upload an image or begin a live broadcast. As their market shares grow, and as users continue to upload pictures of their faces (including those in response to campaigns such as #10yearchallenge) their artificial intelligence models for each one of us becomes increasingly accurate.</p>

<p>Once such recognition technology has been deployed at a global scale, governments of all hues, democratic and authoritarian will sooner or later want to use these capabilities for legal and illegal purposes. For example, a terrorist could be identified at an airport, a criminal could be matched with CCTV footage, an intimidated victim of trafficking can be identified without her cooperation, a missing child who is too young to remember her origins can be united with her parents. Unfortunately, the very same technology can also be used to identify a labour union member on strike, a human rights activist at a demonstration, a sexual minority in a park, and a sex worker at a mall.</p>

<p>Even the employees of these Internet giants seem to be horrified by the potential illegal uses of facial recognition technology by governments. In October last year, 450 Amazon employees protested the licensing of the software, Rekognition, to US government and law enforcement agencies. Amazon ignored these protests and proceeded with closing those deals. Just last week, Satya Nadella at Microsoft indicated that Microsoft would follow suit. He said, "We made a principled decision that we're not going to withhold technology from institutions that we have elected in democracies to protect the freedoms we enjoy."</p>

<p>The digital human rights activists just like the nine judge bench in the Puttaswamy judgment, believe that surveillance must be "necessary and proportionate". A centralised global panopticon capable of identifying billions of humans across the planet fails this test. Therefore, from a human rights perspective, an absolute ban on the provisioning of these technologies to governments makes perfect sense. The internet giants obviously disagree. Last month, Brad Smith, Microsoft's chief legal officer exemplified this position when he said, "A sweeping ban on all government use clearly goes too far and risks being cruel in its humanitarian effect."</p>

<p>Face recognition technologies can be life altering for visually impaired persons. Imagine a visually impaired person attending a book fair or a concert. She would be able to use this technology to identify and speak to her favourite author, expert, commercial partner or friend. Therefore, the optimisation question here is: how can we provide facial recognition technology to the visually impaired person without letting it be abused by the state. Do remember that all of us so called 'able-bodied' are only temporarily abled. Unless we have the double fortune of dying quickly and early we will spend a part of our life disabled and will have to depend on similar electronic accessibility technologies. And even if our bodies don't fail us, our minds will and many of us will find such recognition technology critical as we age. Another clear example is the use of recognition technology to find a missing child.</p>

<p>How can internet giants build face recognition technology with technical guardrails in place? Like Apple they can decide to adopt a decentralised architecture. In others words, the best way for internet giants to prevent abuse of their platforms is to make it technically impossible to do so. The face recognition software can run locally on the user's device, the artificial intelligence models and the relevant data can be stored locally on the user's device. When a visually impaired person is about to attend an event, the event organisers can provide the attendee's data after securing informed consent. When a child goes missing, the parents could share the data for their child with search parties that have volunteered to scour the neighbouring localities and states where the child is likely to be found. This decentralised architecture makes it impossible for a government to use internet giants as a global panopticon. A separation of surveillance capitalism from surveillance state.</p>

<p>Even with such technical guardrails there may be unintended consequences. In China, there is the phenomenon of human flesh search engines, where online mobs hunt down and punish citizens whose actions have enraged them. Therefore, new technical guardrails and institutional checks and balances will need to be introduced as users use and abuse such platforms.</p>

</div>

<button class="copy-btn-full" data-copytarget="#fulltext">Copy Full Text</button>

{% include back-to-top.html %}

## Context and Background

This opinion was published in March 2019 and discusses the civil liberties implications of facial recognition when combined with the reach of Internet platforms. It recommends decentralised technical approaches and institutional checks to prevent a global surveillance panopticon, while recognising accessibility benefits for people with disabilities.

## External Link

- [Read on Business Standard](https://www.business-standard.com/article/opinion/when-governments-tag-you-on-social-media-119031301137_1.html) (Subscription required)

<style>
.media-details {
  background: #f9fbfe;
  border: 1px solid #d8e2f0;
  border-radius: 10px;
  padding: 1.2rem 1.4rem;
  max-width: 700px;
  margin: 1.2rem auto;
  font-size: 0.96rem;
  line-height: 1.5;
  color: #333;
  box-shadow: 0 2px 4px rgba(0,0,0,0.04);
}
.media-details dt {
  font-weight: 600;
  color: #1b2a49;
  margin-top: 0.7rem;
}
.media-details dd {
  margin: 0 0 0.3rem 0.3rem;
  color: #555;
}
.media-image {
  text-align: center;
  margin: 1.5rem auto;
  max-width: 720px;
}
.media-image img {
  width: 100%;
  height: auto;
  border-radius: 8px;
  box-shadow: 0 2px 6px rgba(0,0,0,0.1);
}
.media-image figcaption {
  font-size: 0.9rem;
  color: #555;
  margin-top: 0.5rem;
}
.highlighted-text {
  background-color: #fffbea;
  border-left: 4px solid #f2ce61;
  padding: 1rem 1.2rem;
  border-radius: 8px;
  line-height: 1.65;
  color: #333;
  box-shadow: 0 1px 3px rgba(0,0,0,0.05);
  margin-bottom: 0.8rem;
}
.highlighted-text p {
  margin-bottom: 1rem;
}
.copy-btn-full {
  display: inline-block;
  background: #f1f1f1;
  border: 1px solid #ccc;
  font-size: 0.85rem;
  padding: 0.4rem 0.8rem;
  border-radius: 6px;
  cursor: pointer;
  transition: background 0.2s ease;
  margin-bottom: 1.5rem;
}
.copy-btn-full:hover {
  background: #e5e5e5;
}
</style>

<script>
document.addEventListener('DOMContentLoaded', () => {
  document.querySelectorAll('.copy-btn-full').forEach(button => {
    button.addEventListener('click', async () => {
      const targetSelector = button.getAttribute('data-copytarget');
      const targetElement = document.querySelector(targetSelector);
      if (targetElement) {
        const text = targetElement.innerText.trim();
        await navigator.clipboard.writeText(text);
        button.textContent = 'Copied!';
        setTimeout(() => (button.textContent = 'Copy Full Text'), 1500);
      }
    });
  });
});
</script>
