---
layout: default
title: "Surveillance Project"
description: "A Frontline cover story by Sunil Abraham examining the Aadhaar Act's technological architecture, critiquing biometric centralisation, surveillance risks, and the limits of legal safeguards in large-scale identification systems."
categories: [Media articles, Publications]
date: 2016-03-30
authors: ["Sunil Abraham"]
source: "Frontline"
permalink: /publications/surveillance-project-frontline/
created: 2026-01-22
---

**Surveillance Project** is a *Frontline* cover story published on 30 March 2016 by Sunil Abraham. Written two weeks after Parliament passed the Aadhaar Act, the article provides a systematic technical and political critique of biometric centralisation, and argues that architectural choices, rather than legal safeguards alone, play a decisive role in shaping whether identification systems enable governance or surveillance.

This article was also published as a [chapter](/publications/surveillance-project/) in *Dissent on Aadhaar: Big Data Meets Big Brother*, edited by Reetika Khera (Orient Blackswan, 2018).

## Contents

1. [Article Details](#article-details)
2. [Full Text](#full-text)
3. [Context and Background](#context-and-background)
4. [External Link](#external-link)

## Article Details

<dl class="media-details">
<dt>ðŸ“° Published in:</dt>
<dd><em>Frontline</em></dd>

<dt>ðŸ“… Date:</dt>
<dd>30 March 2016</dd>

<dt>ðŸ‘¤ Author:</dt>
<dd>Sunil Abraham</dd>

<dt>ðŸ“‘ Section:</dt>
<dd>Cover Story</dd>

<dt>ðŸ“„ Type:</dt>
<dd>Opinion / Analysis</dd>

<dt>ðŸ“° Magazine Link:</dt>
<dd>
<a class="btn" href="https://frontline.thehindu.com/cover-story/surveillance-project/article8408866.ece">
Read Online
</a> (Subscription required)
</dd>
</dl>

## Full Text

<div class="highlighted-text" id="fulltext">

<p><strong>Zero</strong>. The probability of some evil actor breaking into the central store of authentication factors (such as keys and passwords) for the Internet. Why? That is because no such store exists. And, what is the probability of someone evil breaking into the Central Identities Data Repository (CIDR) of the Unique Identification Authority of India (UIDAI)? Greater than zero. How do we know this? One, the central store exists and two, the Aadhaar Bill lists breaking into this central store as an offence. Needless to say, it would be redundant to have a law that criminalises a technological impossibility. What is the consequence of someone breaking into the central store? Remember, biometrics is just a fancy word for non-consensual and covert identification technology. High-resolution cameras can capture fingerprints and iris information from a distance.</p>

<p>In other words, on March 16, when Parliament passed the Bill, it was as if Indian lawmakers wrote an open letter to criminals and foreign states saying, "We are going to collect data to non-consensually identify all Indians and we are going to store it in a central repository. Come and get it!" Once again, how do I know that the CIDR will be compromised at some date in the future? How can I make that policy prediction with no evidence to back it up? To quote Sherlock Holmes, "Once you eliminate the impossible, whatever remains, no matter how improbable, must be the truth." If a back door to the CIDR exists for the government, then the very same back door can be used by an enemy within or from outside. In other words, the principle of decentralisation in cybersecurity does not require repeated experimental confirmation across markets and technologies.</p>

<p><strong>Zero</strong>. The chances that you can fix with the law what you have broken with poor technological choices and architecture. And, to a large extent vice versa. Aadhaar is a surveillance project masquerading as a development intervention because it uses biometrics. There is a big difference between the government identifying you and you identifying yourself to the government. Before UID, it was much more difficult for the government to identify you without your knowledge and conscious cooperation. Tomorrow, using high-resolution cameras and the power of big data, the government will be able to remotely identify those participating in a public protest. There will be no more anonymity in the crowd. I am not saying that law-enforcement agencies and intelligence agencies should not use these powerful technologies to ensure national security, uphold the rule of law and protect individual rights. I am only saying that this type of surveillance technology is inappropriate for everyday interactions between the citizen and the state.</p>

<p>Some software engineers believe that there are technical fixes for these concerns; they point to the consent layer in the India stack developed through a public-private partnership with the UIDAI. But this is exactly what Evgeny Morozov has dubbed "technological solutionism"â€”fundamental flaws like this cannot be fixed by legal or technical band-aid. If you were to ask the UIDAI how do you ensure that the data do not get stolen between the enrolment machine and the CIDR, the response would be, we use state-of-the-art cryptography. If cryptography is good enough for the UIDAI why is it not good enough for citizens? That is because if citizens use cryptography [on smart cards] to identify themselves to the state, the state will need their conscious cooperation each time. That provides the feature that is required for better governance without the surveillance bonus. If you really must use biometrics, it could be stored on the smart card after being digitally signed by the enrolment officer. If there is ever a doubt whether the person has stolen the smart card, a special machine can be used to read the biometrics off the card and check that against the person. This way the power of biometrics would be leveraged without any of the accompanying harms.</p>

<p><strong>Zero</strong>. This time, for the utility of biometrics as a password or authentication factor. There are two principal reasons for which the Act should have prohibited the use of biometrics for authentication. First, biometric authentication factors are irrevocable unlike passwords, PINs, digital signatures, etc. Once a biometric authentication factor has been compromised, there is no way to change it. The security of a system secured by biometrics is permanently compromised. Second, our biometrics is so easy to steal; we leave our fingerprints everywhere.</p>

<p>Also, if I upload my biometric data onto the Internet, I can then plausibly deny all transactions against my name in the CIDR. In order to prevent me from doing that, the government will have to invest in CCTV cameras [with large storage] as they do for passport-control borders and as banks do at ATMs. If you anyway have to invest in CCTV cameras, then you might as well stick with digital signatures on smart cards as the previous National Democratic Alliance (NDA) government proposed the SCOSTA (Smart Card Operating System Standard for Transport Application) standard for the MNIC (Multipurpose National ID Card). Leveraging smart card standards like EMV will ensure harnessing greater network effects thanks to the global financial infrastructure of banks. These network effects will drive down the cost of equipment and afford Indians greater global mobility. And most importantly when a digital signature is compromised the user can be issued a new smart card. As Rufo Guerreschi, executive director of Open Media Cluster, puts it, "World leaders and IT experts should realise that citizen freedoms and states' ability to pursue suspects are not an 'either or' but a 'both or neither'."</p>

<p><strong>Near zero</strong>. We now move biometrics as the identification factor. The rate of potential duplicates or "False Positive Identification Rate" which according to the UIDAI is only 0.057 per cent. Which according to them will result in only "570 resident enrolments will be falsely identified as duplicate for every one million enrolments." However, according to an article published in <em>Economic & Political Weekly</em> by my colleague at the Centre for Internet and Society, Hans Varghese Mathews, this will result in one out of every 146 people being rejected during enrolment when total enrolment reaches one billion people. In its rebuttal, the UIDAI disputes the conclusion but offers no alternative extrapolation or mathematical assumptions. "Without getting too deep into the mathematics" it offers an account of "a manual adjudication process to rectify the biometric identification errors".</p>

<p>This manual adjudication determines whether you exist and has none of the elements of natural justice such as notice to the affected party and opportunity to be heard. Elimination of ghosts is impossible if only machines and unaccountable humans perform this adjudication. This is because there is zero skin in the game. There are free tools available on the Internet such as SFinGe (Synthetic Fingerprint Generator) which allow you to create fake biometrics. The USB cables on the UIDAI-approved enrolment setup can be intercepted using generic hardware that can be bought online. With a little bit of clever programming, countless number of ghosts can be created which will easily clear the manual adjudication process that the UIDAI claims will ensure that "no one is denied an Aadhaar number because of a biometric false positive".</p>

<p><strong>Near zero</strong>. This time for surveillance, which I believe should be used like salt in cooking. Essential in small quantities but counterproductive even if slightly in excess. There is a popular misconception that privacy researchers such as myself are opposed to surveillance. In reality, I am all for surveillance. I am totally convinced that surveillance is good anti-corruption technology.</p>

<p>But I also want good returns on investment for my surveillance tax rupee. According to Julian Assange, transparency requirements should be directly proportionate to power; in other words, the powerful should be subject to more surveillance. And conversely, I add, privacy protections must be inversely proportionate to powerâ€”or again, in other words, the poor should be spared from intrusions that do not serve the public interest. The UIDAI makes the exact opposite design assumption; it assumes that the poor are responsible for corruption and that technology will eliminate small-ticket or retail corruption. But we all know that politicians and bureaucrats are responsible for most of large-ticket corruption.</p>

<p>Why does not the UIDAI first assign UID numbers to all politicians and bureaucrats? Then using digital signatures why do not we ensure that we have a public non-repudiable audit trail wherein everyone can track the flow of benefits, subsidies and services from New Delhi to the panchayat office or local corporation office? That will eliminate big-ticket or wholesale corruption. In other words, since most of Aadhaar's surveillance is targeted at the bottom of the pyramid, there will be limited bang for the buck. Surveillance is the need of the hour; we need more CCTVs with microphones turned on in government offices than biometric devices in slums.</p>

<h3>Instantiation technology</h3>

<p><strong>One</strong>. And zero. In the contemporary binary and digital age, we have lost faith in the old gods. Science and its instantiation technology have become the new gods. The cult of technology is intolerant to blasphemy. For example, Shekhar Gupta recently tweeted saying that part of the opposition to Aadhaar was because "left-libs detest science/tech". Technology as ideology is based on some fundamental articles of faith: one, new technology is better than old technology; two, expensive technology is better than cheap technology; three, complex technology is better than simple technology; and four, all technology is empowering or at the very least neutral. Unfortunately, there is no basis in science for any of these articles of faith.</p>

<p>Let me use a simple story to illustrate this. I was fortunate to serve as a member of a committee that the Department of Biotechnology established to finalise the Human DNA Profiling Bill, 2015, which was to be introduced in Parliament in the last monsoon session. Aside: the language of the Act also has room for the database to expand into a national DNA database circumventing 10 years of debate around the controversial DNA Profiling Bill, 2015. The first version of this Bill that I read in January 2013 said that DNA profiling was a "powerful technology that makes it possible to determine whether the source of origin of one body substance is identical to that of another â€¦ without any doubt". In other words, to quote K.P.C. Gandhi, a scientist from Truth Labs, "I can vouch for the scientific infallibility of using DNA profiling for carrying out justice."</p>

<p>Unfortunately, though, the infallible science is conducted by fallible humans. During one of the meetings, a scientist described the process of generating a biometric profile. The first step after the laboratory technician generated the profile was to compare the generated profile with her or his own profile because during the process of loading the machine with the DNA sample, some of the laboratory technician's DNA could have contaminated the sample. This error would not be a possibility in much older, cheaper and rudimentary biometric technology for example, photography. A photographer developing a photograph in a darkroom does not have to ensure that his or her own image has not accidentally ended up on the negative. But the UIDAI is filled with die-hard techno-utopians; if you tell them that fingerprints will not work for those who are engaged in manual labour, they will say then we will use iris-based biometrics. But again, complex technologies are more fragile and often come with increased risks. They may provide greater performance and features, but sometimes they are easier to circumvent. A gummy finger to fool a biometric scanner can be produced using glue and a candle, but to fake a passport takes a lot of sophisticated technology. Therefore, it is important for us as a nation to give up our unquestioning faith in technology and start to debate the exact technological configurations of surveillance technology for different contexts and purposes.</p>

<p><strong>One</strong>. This time representing a monopoly. Prior to the UID project, nobody got paid when citizens identified themselves to the state. While the Act says that the UIDAI will get paid, it does not specify how much. Sooner or later, this cost of identification will be passed on to the citizens and residents. There will be a consumer-service provider relationship established between the citizen and the state when it comes to identification. The UIDAI will become the monopoly provider of identification and authentication services in India which is trusted by the government. That sounds like a centrally planned communist state to me. Should not the right-wing oppose the Act because it prevents the free market from working? Should not the free market pick the best technology and business model for identification and authentication? Will not that drive the cost of identification and authentication down and ensure higher quality of service for citizens and residents?</p>

<h3>Competing providers</h3>

<p>Competing providers can also publish transparency reports regarding their compliance with data requests from law-enforcement and intelligence agencies, and if this is important to consumers they will be punished by the market. The government can use mechanisms such as permanent and temporary bans and price regulation as disincentives for the creation of ghosts. There will be a clear financial incentive to keep the database clean. Just like the government established a regulatory framework for digital certificates in the Information Technology Act allowing for e-commerce and e-governance. Ideally, the Aadhaar Bill should have done something similar and established an ecosystem for multiple actors to provide services in this two-sided market. For it is impossible for a "small government" to have the expertise and experience to run one of the world's largest database of biometric and transaction records securely for perpetuity.</p>

<p>To conclude, I support the use of biometrics. I support government use of identification and authentication technology. I support the use of ID numbers in government databases. I support targeted surveillance to reduce corruption and protect national security. But I believe all these must be put in place with care and thought so that we do not end up sacrificing our constitutional rights or compromising the security of our nation state. Unfortunately, the Aadhaar project's technological design and architecture is an unmitigated disaster and no amount of legal fixes in the Act will make it any better. Our children will pay a heavy price for our folly in the years to come. To quote the security guru Bruce Schneier, "Data is a toxic asset. We need to start thinking about it as such, and treat it as we would any other source of toxicity. To do anything else is to risk our security and privacy."</p>

</div>

<button class="copy-btn-full" data-copytarget="#fulltext">Copy Full Text</button>

{% include back-to-top.html %}

## Context and Background

This Frontline cover story appeared on 30 March 2016, exactly two weeks after Parliament passed the Aadhaar (Targeted Delivery of Financial and Other Subsidies, Benefits and Services) Act on 16 March 2016 as a money billâ€”a controversial procedural maneuver that bypassed Rajya Sabha scrutiny. The Act provided statutory backing to the Unique Identification Authority of India's decade-long biometric enrollment project, which had enrolled over 900 million residents without legislative authorization.

Sunil Abraham's essay employed a rhetorical structure organized around probabilities ("Zero," "Near zero," "One") to systematically dismantle claims that legal safeguards could remedy fundamental architectural flaws in Aadhaar's design. His central argument: technological architectureâ€”not statutory languageâ€”determines whether identification systems enable democratic governance or enable surveillance.

The article's core technical critique centered on centralization. Abraham observed that the internet's authentication infrastructure has zero probability of centralized breach because no central repository of passwords existsâ€”authentication is decentralized by design. Aadhaar inverted this principle by creating the Central Identities Data Repository (CIDR), storing biometric data for over one billion people in a single database. The Act's criminalization of CIDR breaches paradoxically confirmed the system's vulnerabilityâ€”"it would be redundant to have a law that criminalises a technological impossibility."

Sunil Abraham defined biometrics as "non-consensual and covert identification technology"â€”distinguishing it fundamentally from consensual authentication mechanisms. High-resolution cameras could capture fingerprints and iris scans remotely, enabling identification without knowledge or cooperation. Before Aadhaar, citizens could refuse identification by withholding documents; biometric systems eliminated this autonomy. The consequence: "Tomorrow, using high-resolution cameras and the power of big data, the government will be able to remotely identify those participating in a public protest. There will be no more anonymity in the crowd."

Sunil rejected Evgeny Morozov's "technological solutionism"â€”the belief that technical fixes could remedy architectural failures. The India Stack's "consent layer" exemplified this fallacy. If cryptography sufficed to protect data in transit from enrollment kiosks to CIDR, why not empower citizens with cryptography on smart cards? Because smart cards require "conscious cooperation each time"â€”precisely the consent architecture that prevents surveillance whilst enabling governance.

The article referenced CIS colleague Hans Varghese Mathews' Economic & Political Weekly analysis demonstrating that UIDAI's claimed 0.057% False Positive Identification Rate would exclude one in 146 people at one billion enrollmentsâ€”not the 570 per million that UIDAI advertised. UIDAI's rebuttal avoided mathematical engagement, instead proposing "manual adjudication" lacking natural justice elements (notice, hearing). Abraham noted this adjudication was vulnerable to manipulation using freely available tools like SFinGe (Synthetic Fingerprint Generator) and USB interception hardware.

Abraham advocated smart card alternatives, specifically the SCOSTA (Smart Card Operating System Standard for Transport Application) standard proposed by the previous NDA government for the Multipurpose National ID Card. Smart cards leveraging EMV standards would harness global financial infrastructure network effects, reducing equipment costs and enabling international interoperability. Crucially, compromised digital signatures could be revoked and reissuedâ€”unlike biometrics, which are "irrevocable" once stolen.

The essay challenged techno-utopianism through DNA profiling examples from Abraham's service on the Department of Biotechnology's Human DNA Profiling Bill committee. Laboratory technicians checking samples against their own profiles to detect contamination illustrated how "complex technologies are more fragile and often come with increased risks." A gummy finger produced with "glue and a candle" could fool biometric scanners, whilst passport forgery required sophisticated technology.

Abraham inverted conventional surveillance justifications through power analysis inspired by Julian Assange: "transparency requirements should be directly proportionate to power." Privacy protections should be "inversely proportionate to power"â€”the poor deserve protection from intrusions lacking public interest justification. Aadhaar inverted this principle, surveilling welfare recipients ("biometric devices in slums") rather than power-holders. Abraham proposed: "we need more CCTVs with microphones turned on in government offices than biometric devices in slums."

The article critiqued UIDAI's monopoly on identification services, questioning why free-market advocates supported centralized state control. Multiple competing providers could publish transparency reports on law enforcement compliance, enabling market discipline. The Information Technology Act's framework for digital certificates demonstrated how regulatory ecosystems could support multiple authentication providers without monopolistic infrastructure.

Abraham concluded by invoking Bruce Schneier's concept of data as "toxic asset"â€”requiring careful handling to prevent systemic contamination. The Aadhaar Act's passage represented a choice to accumulate unprecedented biometric toxicity in centralized repositories, mortgaging future generations' security for present administrative convenience.

The article's publication timing, immediately following the Act's passage, positioned it as urgent public education for citizens processing the legislation's implications. Many of the architectural arguments articulated in the article later resurfaced in public discourse and legal debates around Aadhaar, including during the Supreme Court hearings in 2017â€“18.

## External Link

- [Read on Frontline](https://frontline.thehindu.com/cover-story/surveillance-project/article8408866.ece) (Subscription required)

<style>
.media-details {
background: #f9fbfe;
border: 1px solid #d8e2f0;
border-radius: 10px;
padding: 1.2rem 1.4rem;
max-width: 700px;
margin: 1.2rem auto;
font-size: 0.96rem;
line-height: 1.5;
color: #333;
box-shadow: 0 2px 4px rgba(0,0,0,0.04);
}
.media-details dt {
font-weight: 600;
color: #1b2a49;
margin-top: 0.7rem;
}
.media-details dd {
margin: 0 0 0.3rem 0.3rem;
color: #555;
}
.highlighted-text {
background-color: #fffbea;
border-left: 4px solid #f2ce61;
padding: 1rem 1.2rem;
border-radius: 8px;
line-height: 1.65;
color: #333;
box-shadow: 0 1px 3px rgba(0,0,0,0.05);
margin-bottom: 0.8rem;
}
.highlighted-text p {
margin-bottom: 1rem;
}
.highlighted-text h3 {
margin-top: 1.5rem;
margin-bottom: 0.8rem;
font-size: 1.15rem;
}
.copy-btn-full {
display: inline-block;
background: #f1f1f1;
border: 1px solid #ccc;
font-size: 0.85rem;
padding: 0.4rem 0.8rem;
border-radius: 6px;
cursor: pointer;
transition: background 0.2s ease;
margin-bottom: 1.5rem;
}
.copy-btn-full:hover {
background: #e5e5e5;
}
.article-separator {
  border: none;
  border-top: 1px solid rgba(0,0,0,0.08);
  margin: 0.75rem 0 1rem 0;
}
</style>

<script>
document.addEventListener('DOMContentLoaded', () => {
document.querySelectorAll('.copy-btn-full').forEach(btn => {
btn.addEventListener('click', async () => {
const target = document.querySelector(btn.getAttribute('data-copytarget'));
if (!target) return;
try {
await navigator.clipboard.writeText(target.innerText.trim());
const original = btn.textContent;
btn.textContent = 'Copied!';
setTimeout(() => (btn.textContent = original), 1500);
} catch (e) {
btn.textContent = 'Copy failed';
setTimeout(() => (btn.textContent = 'Copy Full Text'), 1500);
}
});
});
});
</script>
