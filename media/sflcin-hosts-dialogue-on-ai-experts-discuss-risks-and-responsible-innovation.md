---
layout: default
title: "SFLC.IN Hosts Dialogue on AI: Experts Discuss Risks & Responsible Innovation"
description: "The Quint coverage of SFLC.IN's dialogue on artificial intelligence examining deepfakes, responsible AI practices and governance frameworks, featuring Sunil Abraham's analysis on model explainability and the future of large language models."
categories: [Media mentions]
date: 2024-11-27
source: "The Quint"
permalink: /media/sflcin-hosts-dialogue-on-ai-experts-discuss-risks-and-responsible-innovation/
created: 2025-12-26
---

**SFLC.IN Hosts Dialogue on AI: Experts Discuss Risks & Responsible Innovation** is a news report published by *The Quint* on 27 November 2024 as partner content. The article documents a dialogue on artificial intelligence hosted by the Software Freedom Law Center, India (`SFLC.IN`) at the India Habitat Centre on 25 November 2024. It features commentary from Sunil Abraham, Policy Director at META India, alongside other experts including Mishi Choudhary, Saikat Saha, Pamposh Raina and Udbhav Tiwari, examining challenges around deepfakes, AI governance frameworks, model explainability and the balance between innovation and accountability in India's AI ecosystem.

## Contents

1. [Article Details](#article-details)  
2. [Full Text](#full-text)  
3. [Context and Background](#context-and-background)  
4. [External Link](#external-link)

## Article Details

<dl class="media-details">
  <dt>ðŸ“° Published in:</dt>
  <dd><em>The Quint</em></dd>

  <dt>ðŸ“… Date:</dt>
  <dd>27 November 2024</dd>

  <dt>ðŸ“„ Type:</dt>
  <dd>Event Coverage</dd>

  <dt>ðŸ“° Publication Link:</dt>
  <dd>
    <a class="btn" href="https://www.thequint.com/tech-and-auto/sflcin-on-ai-navigating-risk-regulation-and-responsibility">Read Online</a>
  </dd>
</dl>

## Full Text

<div class="highlighted-text" id="fulltext">

<p>On Monday, 25 November 2024, the Software Freedom Law Center, India (SFLC.IN) hosted a dialogue on artificial intelligence at the India Habitat Centre, bringing together industry leaders, academics, and technology experts. The event, titled <em>AI in Focus: Navigating Risk, Regulation, and Responsibility</em>, featured two panel sessions examining the challenges and opportunities of generative AI and open-source technologies and their impact on technological and social frameworks. <strong>The Quint</strong> was the official media partner for the event.</p>

<p><strong>Mishi Choudhary, Founder of SFLC.IN, set the stage with a compelling opening statement â€”</strong></p>

<blockquote>"SFLC.IN has been working around AI since 2018 when Gen AI was relatively non-existent. We have seen data evolve, from simple pattern-matching software to systems capable of imitating human behaviour; it raises urgent questions about ethics and rights. We must shift from reactive measures to proactive and pro-innovation regulations, but not at the cost of human rights, equity, and environmental sustainability."<br/>
<em>Mishi Choudhary, Founder of SFLC.IN</em></blockquote>

<p>As the panelists shared their insights, the discussion explored the proliferation of deepfakes, the pursuit of responsible AI practices, and the need to navigate India's unique socio-cultural complexities.</p>

<p><strong>Saikat Saha, Technology Director, NASSCOM, highlighted â€”</strong></p>

<blockquote>"At NASSCOM AI, we are shaping technical charters and addressing collective risks to drive responsible AI adoption in India. AI can be an economic game-changer for priority sectors like SMEs. While regulatory uncertainties and geolocalised challenges persist, we focus on fostering open consultations between corporates, MSMEs, and stakeholders."<br/>
<em>Saikat Saha, Technology Director, NASSCOM</em></blockquote>

<p><strong>Pamposh Raina, Head, Deepfakes Analysis Unit (DAU), Misinformation Combat Alliance, said â€”</strong></p>

<blockquote>"Misinformation generated by AI, especially manipulated audio and video, is a growing concern. We analysed over 2,200 media pieces in eight months, revealing significant data misuse during elections, rising health misinformation, and financial fraud. This issue requires a collaborative approach, such as focusing on AI and digital literacy and ensuring platforms flag fake content."<br/>
<em>Pamposh Raina, Head, Deepfakes Analysis Unit (DAU), Misinformation Combat Alliance</em></blockquote>

<p>The conversation then shifted to the balance between innovation and accountability in AI, with panellists shedding light on the nuanced interplay of technology, ethics, and regulation.</p>

<p><strong>Sunil Abraham, Policy Director, META India, emphasised â€”</strong></p>

<blockquote>"LLMs are non-deterministic, and engineers are often racing ahead of scientists with this black box. At Meta, we believe that the future lies in a multiplicity of large and small models that are more accessible, affordable, and capable. The ecosystem must catch up with the regulatory landscape, deploy responsibly, and focus on model explainability, particularly for sensitive use cases like healthcare."<br/>
<em>Sunil Abraham, Policy Director, META India</em></blockquote>

<p><strong>Udbhav Tiwari, Director, Global Product Policy at Mozilla, added â€”</strong></p>

<blockquote>"Open-source AI holds immense potential, but it must be approached with responsibility. Clear definitions and safeguards are important to avoid risks like open washing and ensure alignment with shared norms and values. The deliberate design of these systems and their data comes with a responsibility that laws and institutions must incentivize."<br/>
<em>Udbhav Tiwari, Director, Global Product Policy at Mozilla</em></blockquote>

<p>The panel discussions underscored the urgent need for clear, inclusive AI governance frameworks that suit India's unique context and also aligns with global best practices like the EU's GDPR. The event reinforced the significance of pro-innovation regulations, digital literacy, and stakeholder collaboration in shaping an AI ecosystem. Based on the discussions, SFLC.IN will soon launch its research paper, <em>Harnessing Open Source in AI</em>, which will serve as a cornerstone for all future dialogues and initiatives in shaping responsible AI practices.</p>

<p>The event brought together an outstanding lineup of experts and innovators, including Aindriya Barua, Founder & CEO of Shhor AI; Charles Brecque, Co-Founder & CEO of TextMine; Saikat Saha, Technology Director at NASSCOM; Pamposh Raina, Head of the Deepfakes Analysis Unit at the Misinformation Combat Alliance; Chaitanya Chokkareddy, CTO of Ozonetel Communications; Udbhav Tiwari, Director of Global Product Policy at Mozilla; Smita Gupta, Curator of OpenNY AI; Sunil Abraham, Policy Director at META India; Vukosi Marivate; and Professor Eben Moglen.</p>

<p><strong>About SFLC.IN</strong></p>

<p>SFLC.IN, the Software Freedom Law Center, India, is a non-profit organization committed to safeguarding civil liberties in the digital domain. Its primary focus is advocating for software freedom and digital rights in India. Founded on the principles of freedom, transparency, and equity, SFLC.IN operates at the intersection of law, technology, and society, striving to protect and promote fundamental rights in the digital age.</p>

</div>

<button class="copy-btn-full" data-copytarget="#fulltext">Copy Full Text</button>

{% include back-to-top.html %}

## Context and Background

This dialogue occurred during a pivotal moment when India grappled with the rapid proliferation of generative AI technologies without comprehensive regulatory frameworks. The timing was significant, coming just months after the 2024 Lok Sabha elections that witnessed unprecedented deployment of AI-generated content, including deepfakes targeting political figures and manipulated audio clips spreading across social media platforms.

The Misinformation Combat Alliance's analysis of over 2,200 media pieces in eight months revealed patterns of AI misuse that extended beyond electoral manipulation into health misinformation and financial fraud. This underscored the urgency of establishing governance mechanisms tailored to India's linguistic diversity, digital literacy challenges and federal regulatory structure. Unlike jurisdictions with established AI frameworks such as the European Union's AI Act, India lacked statutory provisions specifically addressing generative AI risks.

Sunil Abraham's emphasis on model explainability reflected growing concerns about the opacity of large language models, particularly as they were being deployed in sensitive domains like healthcare and financial services without adequate transparency mechanisms. His reference to engineers outpacing scientists highlighted a fundamental challenge where deployment timelines prioritised commercial imperatives over rigorous safety testing. Meta's strategy of promoting diverse model architectures rather than concentrating on monolithic systems represented one industry approach to mitigating single-point-of-failure risks.

The discussion around open-source AI and "open washing" addressed a critical debate within the AI development community. Whilst genuinely open-source models offered transparency and community scrutiny, some entities marketed proprietary systems as open-source whilst withholding training data, model weights or inference code. This practice undermined trust and complicated regulatory efforts to distinguish between truly transparent systems and those merely claiming openness for reputational benefits.

SFLC.IN's sustained engagement with AI policy since 2018, predating the ChatGPT-triggered generative AI boom, positioned it uniquely to advocate for rights-based approaches rather than reactive crisis management. The promised research paper *Harnessing Open Source in AI* would contribute to policy discussions at a time when India's Ministry of Electronics and Information Technology was consulting stakeholders on potential AI legislation. The dialogue participants' varied perspectives from industry, civil society and academia reflected the multi-stakeholder approach necessary for crafting effective governance frameworks that balanced innovation incentives with rights protection.

## External Link

- [Read on The Quint](https://www.thequint.com/tech-and-auto/sflcin-on-ai-navigating-risk-regulation-and-responsibility)

<style>
.media-details {
  background: #f9fbfe;
  border: 1px solid #d8e2f0;
  border-radius: 10px;
  padding: 1.2rem 1.4rem;
  max-width: 700px;
  margin: 1.2rem auto;
  font-size: 0.96rem;
  line-height: 1.5;
  color: #333;
  box-shadow: 0 2px 4px rgba(0,0,0,0.04);
}
.media-details dt { font-weight: 600; color: #1b2a49; margin-top: 0.7rem; }
.media-details dd { margin: 0 0 0.3rem 0.3rem; color: #555; }
.highlighted-text {
  background-color: #fffbea;
  border-left: 4px solid #f2ce61;
  padding: 1rem 1.2rem;
  border-radius: 8px;
  line-height: 1.65;
  color: #333;
  margin-bottom: 0.8rem;
}
.highlighted-text p { margin-bottom: 1rem; }
.highlighted-text blockquote {
  background: #f0f4f8;
  border-left: 3px solid #3b82f6;
  padding: 0.7rem 1rem;
  margin: 1rem 0;
  font-style: italic;
  color: #2c3e50;
}
.highlighted-text blockquote em {
  display: block;
  font-style: normal;
  font-weight: 500;
  margin-top: 0.5rem;
  font-size: 0.9rem;
}
.copy-btn-full {
  display: inline-block;
  background: #f1f1f1;
  border: 1px solid #ccc;
  font-size: 0.85rem;
  padding: 0.4rem 0.8rem;
  border-radius: 6px;
  cursor: pointer;
  transition: background 0.2s ease;
  margin-bottom: 1.5rem;
}
.copy-btn-full:hover { background: #e5e5e5; }
.copy-btn-full:focus { outline: 3px solid #ffbf47; outline-offset: 2px; }
</style>

<script>
document.addEventListener('DOMContentLoaded', () => {
  document.querySelectorAll('.copy-btn-full').forEach(btn => {
    btn.addEventListener('click', async () => {
      const target = document.querySelector(btn.getAttribute('data-copytarget'));
      if (!target) return;
      try {
        await navigator.clipboard.writeText(target.innerText.trim());
        const original = btn.textContent;
        btn.textContent = 'Copied!';
        setTimeout(() => (btn.textContent = original), 1500);
      } catch (e) {
        btn.textContent = 'Copy failed';
        setTimeout(() => (btn.textContent = 'Copy Full Text'), 1500);
      }
    });
    btn.addEventListener('keydown', (ev) => {
      if (ev.key === 'Enter' || ev.key === ' ') {
        ev.preventDefault();
        btn.click();
      }
    });
  });
});
</script>
