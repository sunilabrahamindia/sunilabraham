---
layout: default
title: "Regulation Should Build Trust, Not Control, says Dr. Amar Patnaik at 6th Global AI Leadership Meet"
description: "A Varindia report covering the 6th Global AI Leadership Meet 2024 organised by ASSOCHAM, featuring Dr. Amar Patnaik's keynote on trust-based AI regulation and Sunil Abraham's remarks on balanced governance frameworks and open standards."
categories: [Media mentions]
date: 2024-02-21
authors: ["Varindia"]
source: "Varindia"
permalink: /media/ai-regulation-trust-assocham-varindia/
created: 2026-01-06
---

**Regulation Should Build Trust, Not Control, says Dr. Amar Patnaik at 6th Global AI Leadership Meet** is a *Varindia* event report published on 21 February 2024. The article documents proceedings from the 6th Global AI Leadership Meet organised by ASSOCHAM in New Delhi, focusing on the theme "AI for India: Pushing Boundaries for Innovation." The report features Sunil Abraham's analysis of multi-layered AI governance frameworks and advocacy for open standards to protect digital rights.

## Contents

1. [Article Details](#article-details)  
2. [Full Text](#full-text)  
3. [Context and Background](#context-and-background)  
4. [External Link](#external-link)

## Article Details

<dl class="media-details">
  <dt>ðŸ“° Published in:</dt>
  <dd><em>Varindia</em></dd>

  <dt>ðŸ“… Date:</dt>
  <dd>21 February 2024</dd>

  <dt>ðŸ‘¤ Authors:</dt>
  <dd>Varindia</dd>

  <dt>ðŸ“„ Type:</dt>
  <dd>Event Report</dd>

  <dt>ðŸ”— Article Link:</dt>
  <dd>
    <a class="btn" href="https://www.varindia.com/news/regulation-should-build-trust-not-control-says-dr-amar-patnaik-at-6th-global-ai-leadership-meet">
      Read Online
    </a>
  </dd>
</dl>

## Full Text

<div class="highlighted-text" id="fulltext">

<p>"The most important thing about regulation is not to control, but to build trust in the system", stated <strong>Dr. Amar Patnaik, Hon'ble Member of Parliament & Member of Parliament</strong> Standing Committee on Finance, public undertaking and subordinate legislation at the 6th Global AI Leadership Meet 2024, organised by the Associated Chambers of Commerce and Industry of India (ASSOCHAM). In an interactive session titled "AI for India: Pushing Boundaries for Innovation," leaders discussed the transformative potential of artificial intelligence as well as its potential societal impacts.</p>

<p>Dr. Patnaik emphasised how trust is essential for everyone involved and for making sure that the benefits of AI are fair for everyone. He said, "AI has the potential to do a lot of good in society on different levels. Responsible AI means making sure people trust it. Regulations should find a balance between preventing harm and encouraging innovation, all with the goal of building trust. Making AI available to everyone means making sure everyone has access to the data they need. It's important to test new AI ideas in safe environments and to check how they'll affect society. India has a chance to be a leader in AI by using its unique data."</p>

<p>Dr. Patnaik highlighted the problem of big tech companies having most of the data and how it affects competition. He said it's important to give smaller businesses and startups access to data too. He also talked about how governments should encourage sharing data openly and create an environment where new ideas can thrive.</p>

<p>He also said it's important to make AI fit in with the specific situations it's used in. He thinks India can use its different types of data and languages to do this well. He wants companies to use AI responsibly and work together to help achieve important goals for the future.</p>

<p>Dr. Patnaik expressed his backing for Prime Minister Narendra Modi's vision of harnessing AI for India's sustainable development. He highlighted the opportunity in aligning with this vision, emphasizing the potential for India to lead globally through responsible AI practices. Dr. Patnaik pointed out that, similar to achievements in combating climate change, India could drive positive change through AI innovation and a diverse workforce.</p>

<p><strong>Dr. Lovneesh Chanana, Senior Vice President & Regional Head of Government Affairs (Asia Pacific and Japan) at SAP</strong>, highlighted the transition from exploring AI possibilities to implementing practical applications, citing examples such as automated visual inspections. He also discussed the uneven distribution of AI patents globally, emphasizing the need for fair representation. Looking ahead, he stressed the significance of integrating AI into essential business operations and supporting initiatives to enhance AI skills. Dr. Chanana concluded by urging collaborative efforts to navigate the evolving AI landscape responsibly, stating that "The next phase involves integrating AI into fundamental business functions."</p>

<p><strong>Mr. Ashutosh Chadha, Director & Country Head of Corporate Affairs & Public Policy at Microsoft India</strong>, talked about how AI can change our daily lives by making things faster and more impactful. He mentioned that AI is now accessible to everyone, which is a big deal. Mr. Chadha also mentioned concerns about biases and risks in AI, like racial bias and creative biases. He said that because AI doesn't stick to one place or field, we need global rules to manage it. Mr. Chadha believes that countries and industries should work together to make strong rules for AI. He thinks that having a clear plan is important to make sure AI does more good than harm.</p>

<p><strong>Mr. Xavier Kuriyan, Director of Pre-Sales at Dell Technologies</strong>, talked about how AI could boost India's economy by a trillion dollars by 2035. He explained Dell's strategy, which involves using AI in various ways like integration, innovation, process improvement, and working together with others. Mr. Kuriyan stressed the importance of using existing models quickly and developing local solutions step by step. He's optimistic about India's ability to use AI, mentioning our skilled workforce and how AI is becoming more important in how we work. He thinks that AI will become more common and bring new ideas faster.</p>

<p><strong>Mr. Sunil Abraham, Co-Chair of ASSOCHAM National Council on IT/ITes and eCommerce & Public Policy Director at Meta</strong>, mentioned that while AI has risks, it's not helpful to exaggerate them. He suggested that we should have balanced views on regulating AI, using the example of animated drawings. Abraham talked about four levels of AI control: companies taking responsibility, industries setting their own rules, governments making rules, and laws being passed. He talked about the importance of existing laws and Meta's dataset of casual conversations to reduce biases. Abraham supported the idea of having open standards and open science, especially for Indian government groups, to make sure AI is used fairly and to protect digital rights.</p>

</div>

<button class="copy-btn-full" data-copytarget="#fulltext">Copy Full Text</button>

{% include back-to-top.html %}

## Context and Background

This event occurred during a critical phase in India's development of AI governance frameworks. Throughout 2023-2024, the government oscillated between promotional policies encouraging AI innovation and reactive attempts to regulate perceived harms, creating regulatory uncertainty for industry stakeholders.

ASSOCHAM's choice of themeâ€”"AI for India: Pushing Boundaries for Innovation"â€”reflected tensions between maximising AI's economic potential and addressing societal risks. With projections suggesting AI could add a trillion dollars to India's economy by 2035, business interests favoured light-touch regulation that wouldn't stifle innovation. Civil society organisations countered that inadequate safeguards risked entrenching algorithmic discrimination and undermining democratic processes.

Dr. Patnaik's emphasis on "trust-based" rather than "control-based" regulation offered a conceptual middle path, though translating this principle into concrete policy remained contentious. His identification of data concentration amongst large technology companies touched a fundamental challenge: India's vast data generation capabilitiesâ€”stemming from over 700 million internet usersâ€”primarily benefited multinational corporations rather than domestic enterprises or public institutions.

The data access problem Patnaik highlighted had regulatory dimensions. Existing competition frameworks inadequately addressed digital platform dominance, whilst privacy protections remained fragmented across sectoral regulations. Startups and smaller businesses lacked technical infrastructure to process large datasets even when theoretically available, creating structural barriers beyond legal access rights.

Abraham's four-tiered governance modelâ€”corporate responsibility, industry self-regulation, government guidelines, and statutory lawâ€”acknowledged that different AI applications required calibrated responses. His caution against "exaggerating" AI risks likely referenced alarmist narratives about artificial general intelligence that distracted from immediate concerns like algorithmic bias in credit scoring or employment decisions.

The advocacy for open standards and open science particularly resonated with government technology initiatives. India's Digital Public Infrastructure approachâ€”exemplified by unified payment systems and identity frameworksâ€”demonstrated how open architectures could enable innovation whilst maintaining public oversight. Applying similar principles to AI datasets and model development could theoretically democratise access beyond proprietary corporate ecosystems.

Meta's dataset of "casual conversations" Abraham referenced aimed to train language models on diverse speech patterns, addressing concerns that AI systems predominantly reflected Western linguistic norms and cultural assumptions. For India's multilingual contextâ€”with 22 scheduled languages and hundreds of dialectsâ€”ensuring AI systems understood regional variations presented both technical challenges and equity imperatives.

Microsoft's Chadha raising concerns about racial and creative biases acknowledged that AI systems trained on historical data often perpetuated existing prejudices. Without deliberate interventions during development and deployment, these tools risked automating discrimination at scale across hiring, lending, policing, and public services.

The regulatory landscape remained fluid following this event. In March 2024, the government issued an advisory requiring explicit permission before deploying "unreliable" AI modelsâ€”a directive so vaguely worded that it prompted immediate industry backlash. The subsequent withdrawal and replacement with softer guidance illustrated policymakers' struggle to balance innovation promotion with risk mitigation, precisely the challenge Patnaik's trust-based framework sought to address.

## External Link

- <a href="https://www.varindia.com/news/regulation-should-build-trust-not-control-says-dr-amar-patnaik-at-6th-global-ai-leadership-meet">Read on Varindia</a>

<style>
/* ===============================
   Media Article Styles (Unified)
   =============================== */

/* --- Article Details Box --- */
.media-details {
  background: #f9fbfe;
  border: 1px solid #d8e2f0;
  border-radius: 10px;
  padding: 1.2rem 1.4rem;
  max-width: 700px;
  margin: 1.2rem auto;
  font-size: 0.96rem;
  line-height: 1.5;
  color: #333;
  box-shadow: 0 2px 4px rgba(0,0,0,0.04);
}
.media-details dt {
  font-weight: 600;
  color: #1b2a49;
  margin-top: 0.7rem;
}
.media-details dd {
  margin: 0 0 0.3rem 0.3rem;
  color: #555;
}

/* --- Responsive Image --- */
.media-image {
  text-align: center;
  margin: 1.5rem auto;
  max-width: 720px;
  width: 100%;
}
.media-image img {
  display: block;
  width: 100%;
  height: auto;
  max-width: 100%;
  border-radius: 8px;
  box-shadow: 0 2px 6px rgba(0,0,0,0.1);
  object-fit: contain;
}
.media-image figcaption {
  font-size: 0.9rem;
  color: #555;
  margin-top: 0.5rem;
  padding: 0 0.5rem;
}
@media (max-width: 768px) {
  .media-image {
    margin: 1rem auto;
  }
  .media-image img {
    border-radius: 6px;
  }
}

/* --- Highlighted Full Text Box --- */
.highlighted-text {
  background-color: #fffbea;
  border-left: 4px solid #f2ce61;
  padding: 1rem 1.2rem;
  border-radius: 8px;
  line-height: 1.65;
  color: #333;
  box-shadow: 0 1px 3px rgba(0,0,0,0.05);
  margin-bottom: 0.8rem;
}
.highlighted-text p {
  margin-bottom: 1rem;
}

/* --- Copy Full Text Button --- */
.copy-btn-full {
  display: inline-block;
  background: #f1f1f1;
  border: 1px solid #ccc;
  font-size: 0.85rem;
  padding: 0.4rem 0.8rem;
  border-radius: 6px;
  cursor: pointer;
  transition: background 0.2s ease;
  margin-bottom: 1.5rem;
}
.copy-btn-full:hover {
  background: #e5e5e5;
}

/* --- Generic Button (for Article Links etc.) --- */
a.btn {
  display: inline-block;
  background: #3278d6;
  color: #fff !important;
  text-decoration: none;
  padding: 0.4rem 0.8rem;
  border-radius: 5px;
  font-size: 0.9rem;
  transition: background 0.2s ease;
}
a.btn:hover {
  background: #255ea9;
}
</style>

<script>
document.addEventListener('DOMContentLoaded', () => {
  document.querySelectorAll('.copy-btn-full').forEach(button => {
    button.addEventListener('click', async () => {
      const targetSelector = button.getAttribute('data-copytarget');
      const targetElement = document.querySelector(targetSelector);
      if (targetElement) {
        const text = targetElement.innerText.trim();
        await navigator.clipboard.writeText(text);
        button.textContent = 'Copied!';
        setTimeout(() => (button.textContent = 'Copy Full Text'), 1500);
      }
    });
  });
});
</script>
